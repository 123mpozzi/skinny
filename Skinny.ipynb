{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VoQkmwq6jHtx"
   },
   "source": [
    "<a name=\"Table-of-Contents\"></a>\n",
    "# Table of Contents\n",
    "1. [Introduction](#Introduction)\n",
    "    1. [Outcomes](#Outcomes)\n",
    "    1. [Performance](#Performance)\n",
    "    1. [Network Architecture](#Network-Architecture)\n",
    "    1. [Setup](#Setup)\n",
    "    1. [Public Datasets Supported](#Public-Datasets-Supported)\n",
    "    1. [System Info](#System-Info)\n",
    "1. [Settings](#Settings)\n",
    "1. [Datasets Importing](#Datasets-Importing)\n",
    "    1. [Dataset Organization Utils](#Dataset-Organization-Utils)\n",
    "    1. [Generate Datasets CSV Metadata](#Generate-Datasets-CSV-Metadata)\n",
    "1. [Define Skin Detector](#Define-Skin-Detector)\n",
    "    1. [Architecture](#Architecture)\n",
    "    1. [Model Settings](#Model-Settings)\n",
    "    1. [Model Functions](#Model-Functions)\n",
    "1. [Use Skin Detector](#Use-Skin-Detector)\n",
    "    1. [Train](#Train)\n",
    "    1. [Test](#Test)\n",
    "    1. [Predict](#Predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bwTh3AAAjHt4"
   },
   "source": [
    "<a name=\"Introduction\"></a>\n",
    "# Introduction\n",
    "[[Return to ToC]](#Table-of-Contents)\n",
    "\n",
    "Detecting human skin using a U-Net.  \n",
    "\n",
    "#### Original Paper\n",
    "T. Tarasiewicz, J. Nalepa, and M. Kawulok. “Skinny: A Lightweight U-net for Skin Detection and Segmentation”. In: 2020 IEEE International Conference on Image Processing (ICIP). IEEE. 2020, pp. 2386–2390. https://doi.org/10.1109/ICIP40778.2020.9191209.\n",
    "\n",
    "#### Credits\n",
    "Credits to the authors of the original version: \n",
    "https://github.com/ttarasiewicz/Skinny\n",
    "\n",
    "\n",
    "<a name=\"Outcomes\"></a>\n",
    "### Outcomes\n",
    "[[Return to ToC]](#Table-of-Contents)\n",
    "\n",
    "![Outcomes](docs/outcomes.png \"Outcomes\")\n",
    "> Significant outcomes: (a) the input image; (b) the ground truth; (c) Skinny's binarized prediction.  \n",
    "Predictions have different dimensions than other images due to the network preprocessing.  \n",
    "Input images are from ECU, HGR, and Schmugge datasets.\n",
    "Various models have been used to detect skin pixels.\n",
    "\n",
    "\n",
    "These are some significant outcomes (so not representative; for the skin detector performance see [Performance](#Performance))\n",
    "that shows how well the skin detector performs given the right training dataset,\n",
    "but also its limitations.  \n",
    "Skin Detection is a challenging task because of materials with a skin-like colors (wood, copper, leather, clay),\n",
    "conditions that modify an image appearance (lighting, camera color science, motion blur),\n",
    "and the wide range of skin tones that the human skin may assume.  \n",
    "\n",
    "The first, third, and the last three rows represent some of the challenges described.  \n",
    "The U-Net has the capability of extracting features from images, hence it can detect that there are no skin pixels\n",
    "in the fifth row, despite it can contain pixels with skin-like color. \n",
    "\n",
    "An in-depth analysis of outcomes can be seen in the thesis.\n",
    "\n",
    "\n",
    "<a name=\"Performance\"></a>\n",
    "### Performance\n",
    "[[Return to ToC]](#Table-of-Contents)\n",
    "\n",
    "Apart from the Validation process, which uses the original paper methodologies, the metrics are calculated as follows.  \n",
    "Initially, the metrics are measured for all the instances, then the average and population standard\n",
    "deviation for each metric are computed.\n",
    "\n",
    "Again, an in-depth analysis of performance can be seen in the thesis.\n",
    "\n",
    "#### Validation\n",
    "Before the evaluation process on the chosen datasets, the skin detector has been validated on the datasets splits used in its original paper. In this way, it has been possible to check their proper functioning. The original paper calculates the F1-Score directly as the average score over all the set of instances.\n",
    "\n",
    "|             | HGR<sup>1</sup> F<sub>1</sub>-Score | ECU<sup>2</sup> F<sub>1</sub>-Score |\n",
    "| ---:            | :---:              | :---:  |\n",
    "| Original        | 0.9494             | 0.9230 |\n",
    "| Implementation  | 0.9308             | 0.9133 |\n",
    "| | |\n",
    "| Change          | 0.0186             | 0.0097 |\n",
    "> <sup>1</sup>HGR consists of: HGR1, HGR2A-downscaled, HGR2B-downscaled.  \n",
    "<sup>2</sup>ECU was split accordingly to the original work of the method.  \n",
    "The model was trained on the ECU splits; HGR has not been used for training.  \n",
    "The testing was performed on the test set of ECU and the entirety of HGR.\n",
    "\n",
    "#### Performance on single databases\n",
    "For each dataset: the skin detector is trained on the training set, and then predictions are performed on the test set.  \n",
    "For example, with ECU as the dataset, it means that the skin detector is trained using the training set of ECU, and then tested on the test set of ECU.\n",
    "\n",
    "|             | ECU | HGR | Schmugge |\n",
    "| ---:            | :---:              | :---:  | :---: |\n",
    "| F<sub>1</sub> ↑       | 0.9133 ± 0.08 | 0.9848 ± 0.02 | 0.6121 ± 0.45 |\n",
    "| IoU ↑                 | 0.8489 ± 0.12 | 0.9705 ± 0.03 | 0.5850 ± 0.44 |\n",
    "| D<sub>prs</sub> ↓     | 0.1333 ± 0.12 | 0.0251 ± 0.03 | 0.5520 ± 0.64 |\n",
    "\n",
    "#### Performance across databases\n",
    "For each dataset: the skin detector is trained on the training set, and then predictions are performed on all the images of every other datasets.  \n",
    "For example, with ECU as the training dataset and HGR as the testing dataset, it means\n",
    "that the skin detector is trained using the training set of ECU, and then tested on all the HGR\n",
    "dataset.  \n",
    "The expression “HGR on ECU”\n",
    "describes the situation in which the evaluation is performed by using HGR as the training set and ECU as the test set.\n",
    "\n",
    "|             | ECU_on_HGR | ECU_on_Schmugge | HGR_on_ECU | HGR_on_Schmugge | Schmugge_on_ECU | Schmugge_on_HGR |\n",
    "| ---: | :---: | :---: | :---: | :---: | :---: | :---: |\n",
    "| F<sub>1</sub> ↑       | 0.9308 ± 0.11 | 0.4625 ± 0.41 | 0.7252 ± 0.20 | 0.2918 ± 0.31 | 0.6133 ± 0.21 | 0.8106 ± 0.19 |\n",
    "| IoU ↑                 | 0.8851 ± 0.15 | 0.3986 ± 0.37 | 0.6038 ± 0.22 | 0.2168 ± 0.25 | 0.4754 ± 0.22 | 0.7191 ± 0.23 |\n",
    "| D<sub>prs</sub> ↓     | 0.1098 ± 0.15 | 0.7570 ± 0.56 | 0.3913 ± 0.26 | 0.9695 ± 0.44 | 0.5537 ± 0.27 | 0.2846 ± 0.27 |\n",
    "| F<sub>1</sub> - IoU ↓ | 0.0457 | 0.0639 | 0.1214 | 0.0750 | 0.1379 | 0.0915 |\n",
    "\n",
    "#### Performance on single skin tones\n",
    "The methodology is the same as of 'Performance on single databases', but skin tones datasets are involved instead.\n",
    "\n",
    "|             | DARK | MEDIUM | LIGHT\n",
    "| ---:            | :---:              | :---:  | :---: |\n",
    "| F<sub>1</sub> ↑       | 0.9529 ± 0.00 | 0.9260 ± 0.15 | 0.9387 ± 0.12 |\n",
    "| IoU ↑                 | 0.9100 ± 0.01 | 0.8883 ± 0.18 | 0.9006 ± 0.14 |\n",
    "| D<sub>prs</sub> ↓     | 0.0720 ± 0.01 | 0.1078 ± 0.21 | 0.0926 ± 0.15 |\n",
    "\n",
    "#### Performance across skin tones\n",
    "The methodology is the same as of 'Performance across databases', but skin tones datasets are involved instead.\n",
    "\n",
    "|             | DARK_on_MEDIUM | DARK_on_LIGHT | MEDIUM_on_DARK | MEDIUM_on_LIGHT | LIGHT_on_DARK | LIGHT_on_MEDIUM |\n",
    "| ---: | :---: | :---: | :---: | :---: | :---: | :---: |\n",
    "| F<sub>1</sub> ↑       | 0.7300 ± 0.25 | 0.7262 ± 0.26 | 0.8447 ± 0.13 | 0.8904 ± 0.14 | 0.7660 ± 0.17 | 0.9229 ± 0.11 |\n",
    "| IoU ↑                 | 0.6279 ± 0.27 | 0.6276 ± 0.28 | 0.7486 ± 0.15 | 0.8214 ± 0.16 | 0.6496 ± 0.21 | 0.8705 ± 0.13 |\n",
    "| D<sub>prs</sub> ↓     | 0.3805 ± 0.33 | 0.3934 ± 0.34 | 0.2326 ± 0.17 | 0.1692 ± 0.18 | 0.3402 ± 0.21 | 0.1192 ± 0.16 |\n",
    "| F<sub>1</sub> - IoU ↓ | 0.1021 | 0.0986 | 0.0961 | 0.0690 | 0.1164 | 0.0524 |\n",
    "\n",
    "\n",
    "<a name=\"Skin-Detection-Algorithm\"></a>\n",
    "### Network Architecture\n",
    "[[Return to ToC]](#Table-of-Contents)\n",
    "\n",
    "\n",
    "![Skinny Architecture](docs/skinny_architecture.png \"Skinny Architecture\")\n",
    "> The architecture of Skinny. Adapted from the original paper (Tarasiewicz et al. 2020) \n",
    "\n",
    "The Skinny network consists of a modified U-Net incorporating dense\n",
    "blocks and inception modules to benefit from a wider spatial context.  \n",
    "An additional deep level is appended to the original U-Net model,\n",
    "to better capture large-scale contextual features in the deepest\n",
    "part of the network.  \n",
    "The features extracted in the contracting path propagate to the\n",
    "corresponding expansive levels through the dense blocks.  \n",
    "The original U-Net convolutional layers are replaced with\n",
    "the inception modules: before each max-pooling layer, in the contracting path,\n",
    "and after concatenating features, in the expanding path.  \n",
    "Thanks to these architectural choices, Skinny benefits from a wider pixel context.\n",
    "\n",
    "\n",
    "<a name=\"Setup\"></a>\n",
    "### Setup\n",
    "[[Return to ToC]](#Table-of-Contents)\n",
    "\n",
    "Things to Note:  \n",
    "The notebook has only been used in Google Colab, so it may need some modifications to use locally.  \n",
    "Pre-defined splits can be found in the folders of provided models.\n",
    "\n",
    "1. Zip datasets without adding any intermediate folder and upload them into Google Drive\n",
    "2. Upload any pre-trained model into Google Drive\n",
    "3. Change paths of models and datasets in the [Settings](#Settings) section  \n",
    "4. Change paths of pre-defined splits in the [Generate Datasets CSV Metadata](#Generate-Datasets-CSV-Metadata) section \n",
    "5. To use the skin detector, run all code till the [Use Skin Detector](#Use-Skin-Detector) section and change final settings, which are the few first lines of each function of the skin detector  \n",
    "\n",
    "\n",
    "<a name=\"Public-Datasets-Supported\"></a>\n",
    "### Public Datasets Supported\n",
    "[[Return to ToC]](#Table-of-Contents)\n",
    "\n",
    "[ecu]: https://documents.uow.edu.au/~phung/download.html \"ECU download page\"\n",
    "[hgr]: http://sun.aei.polsl.pl/~mkawulok/gestures/ \"HGR download page\"\n",
    "[schmugge]: https://www.researchgate.net/publication/257620282_skin_image_Data_set_with_ground_truth \"Schmugge download page\"\n",
    "[pratheepan]: http://cs-chan.com/downloads_skin_dataset.html \"Pratheepan download page\"\n",
    "[abd]: https://github.com/MRE-Lab-UMD/abd-skin-segmentation \"abd-skin download page\"\n",
    "[vpu]: http://www-vpu.eps.uam.es/publications/SkinDetDM/#dataset \"VPU download page\"\n",
    "[uchile]: http://web.archive.org/web/20070707151628/http://agami.die.uchile.cl/skindiff/ \"UChile download page\"\n",
    "\n",
    "| Name            |  Description                                               | Download |\n",
    "| ---:            | :---:                                                      | :---: |\n",
    "| ECU [1]         | 3998 pictures, mostly face and half-body shots             | [Download (ask the authors)][ecu] |\n",
    "| HGR [2]         | 1558 hand gesture images                                   | [Download][hgr] |\n",
    "| Schmugge [3]    | 845 images, mostly face shots                              | [Download][schmugge] |\n",
    "| Pratheepan [4]  | 78 pictures randomly sampled from the web                  | [Download][pratheepan] |\n",
    "| abd [5]         | 1400 abdominal pictures                                    | [Download][abd] |\n",
    "| VPU [6]         | 285 human activity recognition images                      | [Download][vpu] |\n",
    "| UChile [7]      | 101 images obtained from the web and digitized news videos | [Download][uchile] |\n",
    "\n",
    "\n",
    "| Ref   | Publication |\n",
    "| :---  | :--- |\n",
    "| 1     | Phung, S., Bouzerdoum, A., & Chai, D. (2005). Skin segmentation using color pixel classification: analysis and comparison. IEEE Transactions on Pattern Analysis and Machine Intelligence, 27(1), 148-154. https://doi.org/10.1109/tpami.2005.17  |\n",
    "| 2 | Kawulok, M., Kawulok, J., Nalepa, J., & Smolka, B. (2014). Self-adaptive algorithm for segmenting skin regions. EURASIP Journal on Advances in Signal Processing, 2014(1). https://doi.org/10.1186/1687-6180-2014-170 |\n",
    "| 3 | Schmugge, S. J., Jayaram, S., Shin, M. C., & Tsap, L. V. (2007). Objective evaluation of approaches of skin detection using ROC analysis. Computer Vision and Image Understanding, 108(1-2), 41-51. https://doi.org/10.1016/j.cviu.2006.10.009 |\n",
    "| 4 | Tan, W. R., Chan, C. S., Yogarajah, P., & Condell, J. (2012). A Fusion Approach for Efficient Human Skin Detection. IEEE Transactions on Industrial Informatics, 8(1), 138-147. https://doi.org/10.1109/tii.2011.2172451 |\n",
    "| 5 | Topiwala, A., Al-Zogbi, L., Fleiter, T., & Krieger, A. (2019). Adaptation and Evaluation of Deep Learning Techniques for Skin Segmentation on Novel Abdominal Dataset. 2019 IEEE 19th International Conference on Bioinformatics and Bioengineering (BIBE). https://doi.org/10.1109/bibe.2019.00141 |\n",
    "| 6 | SanMiguel, J. C., & Suja, S. (2013). Skin detection by dual maximization of detectors agreement for video monitoring. Pattern Recognition Letters, 34(16), 2102-2109. https://doi.org/10.1016/j.patrec.2013.07.016 |\n",
    "| 7 | J. Ruiz-del-Solar and R. Verschae. “SKINDIFF-Robust and fast skin segmentation”. Department of Electrical Engineering, Universidad de Chile, 2006. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R4SmknMxjHt_"
   },
   "source": [
    "<a name=\"System-Info\"></a>\n",
    "### System Info\n",
    "[[Return to ToC]](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4wWuJLG8FFDI"
   },
   "source": [
    "Check Python, Tensorflow, CUDA versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RQtNt5byE3W5",
    "outputId": "c8ab224c-0c45-4893-c315-9c9903908db2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.10\n",
      "2021-05-23 19:18:24.481383: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2.4.1\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2020 NVIDIA Corporation\n",
      "Built on Wed_Jul_22_19:09:09_PDT_2020\n",
      "Cuda compilation tools, release 11.0, V11.0.221\n",
      "Build cuda_11.0_bu.TC445_37.28845127_0\n"
     ]
    }
   ],
   "source": [
    "!python --version\n",
    "!python3 -c 'import tensorflow as tf; print(tf.__version__)'\n",
    "!nvcc -V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L60opnpajHuE"
   },
   "source": [
    "<a name=\"Settings\"></a>\n",
    "# Settings\n",
    "[[Return to ToC]](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "DeEQxvn9jHuF"
   },
   "outputs": [],
   "source": [
    "#  Pre-trained models paths\n",
    "models = {}\n",
    "models['ecu'] = 'drive/MyDrive/training/skinny/checkpoint-20210428-155148/saved_model.ckpt/saved_model.pb'\n",
    "models['schmugge'] = 'drive/MyDrive/training/skinny/checkpoint-20210505-225202/saved_model.ckpt/saved_model.pb'\n",
    "models['hgr'] = 'drive/MyDrive/training/skinny/checkpoint-20210512-220723/saved_model.ckpt/saved_model.pb'\n",
    "models['dark'] = 'drive/MyDrive/training/skinny/checkpoint-20210523-110554/saved_model.ckpt/saved_model.pb'\n",
    "models['medium'] = 'drive/MyDrive/training/skinny/checkpoint-20210523-112308/saved_model.ckpt/saved_model.pb'\n",
    "models['light'] = 'drive/MyDrive/training/skinny/checkpoint-20210523-122027/saved_model.ckpt/saved_model.pb'\n",
    "\n",
    "#  Datasets paths\n",
    "datasets = {}\n",
    "datasets['_imports'] = 'drive/MyDrive/datasets/imports/dataset_imports.zip'\n",
    "datasets['ecu'] = 'drive/MyDrive/datasets/fullbody/ECU.zip'\n",
    "datasets['schmugge'] = 'drive/MyDrive/datasets/face/Schmugge.zip'\n",
    "datasets['hgr'] = 'drive/MyDrive/datasets/hand/HGR_small.zip'\n",
    "datasets['schmugge_darkaug'] = 'drive/MyDrive/schm/Schmugge.zip'\n",
    "datasets['vpu'] = 'drive/MyDrive/datasets/fullbody/VDM.zip'\n",
    "datasets['uchile'] = 'drive/MyDrive/datasets/fullbody/Uchile.zip'\n",
    "datasets['pratheepan'] = 'drive/MyDrive/datasets/fullbody/Pratheepan.zip'\n",
    "datasets['abd'] = 'drive/MyDrive/datasets/abdomen/abd-skin.zip'\n",
    "\n",
    "#  Datasets zips to import and extract to folders\n",
    "#  no need to include \"imports\" as it is always unzipped\n",
    "to_import = ['ecu', 'hgr', 'schmugge', 'pratheepan']\n",
    "\n",
    "#  Valid skintone values\n",
    "skintones = ['light', 'medium', 'dark']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yuumSeLG01am"
   },
   "source": [
    "<a name=\"Datasets-Importing\"></a>\n",
    "# Datasets Importing\n",
    "[[Return to ToC]](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bqim8bsQjHuH"
   },
   "source": [
    "Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aRm1MbAk01q3",
    "outputId": "e0a4d2bd-7f83-4bdc-cdba-744cb86837ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qp3GYPvMCciv"
   },
   "source": [
    "Extract the dataset(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FXWRZ3UjdOQh",
    "outputId": "821b67a6-0a5a-4064-c4d7-97eb9dbc76fc"
   },
   "outputs": [],
   "source": [
    "!rm -rf dataset\n",
    "\n",
    "_imports = datasets['_imports']\n",
    "\n",
    "#  Always unzip \"imports\" as it is necessary to import other datasets\n",
    "!unzip $_imports -d dataset\n",
    "\n",
    "for db in to_import:\n",
    "    if db == 'schmugge_darkaug':\n",
    "        !rm -rf dataset/Schmugge\n",
    "    current_db = datasets[db]\n",
    "    !unzip $current_db -d dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Khw4fujbYapP"
   },
   "source": [
    "<a name=\"Dataset-Organization-Utils\"></a>\n",
    "### Dataset Organization Utils\n",
    "[[Return to ToC]](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4HiGrhHRjHuJ"
   },
   "source": [
    "General Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "KgRSkV2sjHuJ"
   },
   "outputs": [],
   "source": [
    "import os, re, sys, json, traceback\n",
    "import cv2\n",
    "import imghdr\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "from math import floor\n",
    "\n",
    "#  Remember that Pratheepan dataset has one file with comma in its filename\n",
    "csv_sep = '?'\n",
    "\n",
    "\n",
    "def get_timestamp() -> str:\n",
    "    return time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "def read_csv(csv_file) -> list:\n",
    "    '''Return the multi-column content of the dataset CSV file'''\n",
    "    file_content = None\n",
    "    try: #  may fail on accessing CSV file: eg. file does not exist\n",
    "        file = open(csv_file)\n",
    "        file_content = file.read().splitlines() #  multi-column file\n",
    "        file.close()\n",
    "    except Exception:\n",
    "        print(traceback.format_exc())\n",
    "        print('Error on accessing ' + csv_file)\n",
    "        exit()\n",
    "    return file_content\n",
    "\n",
    "def split_csv_fields(row: str) -> list:\n",
    "    return row.split(csv_sep)\n",
    "\n",
    "def to_csv_row(*args) -> str:\n",
    "    row = args[0]\n",
    "    for item in args[1:]:\n",
    "        row += csv_sep\n",
    "        row += item\n",
    "    row += '\\n'\n",
    "    return row\n",
    "\n",
    "def match_rows(csv_file: str, targets: list, target_column: int) -> list:\n",
    "    '''Return all rows matching targets in the given column'''\n",
    "    csv_content = read_csv(csv_file)\n",
    "    data = [x for x in csv_content if split_csv_fields(x)[target_column] in targets]\n",
    "    return data\n",
    "\n",
    "def csv_full_test(csv_file: str, count_: int = -1):\n",
    "    '''Overwrite the first count_ note attributes of CSV rows as test notes'''\n",
    "    file_content = read_csv(csv_file)\n",
    "    with open(csv_file, 'w') as out: #  rewrite csv file\n",
    "        for i, entry in enumerate(file_content):\n",
    "            csv_fields = split_csv_fields(entry)\n",
    "            note = 'te'\n",
    "            if count_ != -1 and i >= count_: #  count is disabled if == -1\n",
    "                    note = 'tr'\n",
    "            csv_fields[2] = note\n",
    "            out.write(to_csv_row(*csv_fields))\n",
    "\n",
    "def csv_not_test(csv_file: str):\n",
    "    '''All the rows with note \"te\" become \"tr\", all the rows with note != \"te\", become \"te\"'''\n",
    "    file_content = read_csv(csv_file)\n",
    "    with open(csv_file, 'w') as out: #  rewrite csv file\n",
    "        for entry in file_content:\n",
    "            csv_fields = split_csv_fields(entry)\n",
    "            nt = csv_fields[2]\n",
    "            note = 'tr' if nt == 'te' else 'te'\n",
    "            csv_fields[2] = note\n",
    "            out.write(to_csv_row(*csv_fields))\n",
    "\n",
    "def get_training_and_testing_sets(file_list: list, split: float = 0.7):\n",
    "    print(file_list)\n",
    "    split_index = floor(len(file_list) * split)\n",
    "    training = file_list[:split_index]\n",
    "    testing = file_list[split_index:]\n",
    "    return training, testing\n",
    "\n",
    "def get_variable_filename(filename: str, format: str) -> str:\n",
    "    '''Get the variable part of a filename into a dataset'''\n",
    "    if format == '':\n",
    "        return filename\n",
    "\n",
    "    #  debug:\n",
    "    #  re.fullmatch(r'^img(.*)$', 'imgED (1)').group(1)\n",
    "    #  re.fullmatch(r'^(.*)-m$', 'att-massu.jpg-m').group(1)\n",
    "    match =  re.fullmatch('^{}$'.format(format), filename)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        #print('Cannot match {} with pattern {}'.format(filename, format))  #  debug\n",
    "        return None\n",
    "\n",
    "def is_image(path: str) -> bool:\n",
    "    return os.path.isfile(path) and imghdr.what(path) != None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PFYbnJ4wjHuK"
   },
   "source": [
    "Datasets importing utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "lRSrKTsKjHuK"
   },
   "outputs": [],
   "source": [
    "def analyze_dataset(gt: str, ori: str, root_dir: str, note: str = 'nd',\n",
    "                    gt_filename_format: str = '', ori_filename_format: str = '') -> None:\n",
    "    '''Create CSV file containing dataset metadata (such as paths of images)'''\n",
    "    out_analysis_filename = 'data.csv'\n",
    "    out_file = os.path.join(root_dir, out_analysis_filename)\n",
    "    \n",
    "    #  Number of images found\n",
    "    i = 0\n",
    "\n",
    "    #  Append to data file\n",
    "    with open(out_file, 'a') as out:\n",
    "        for gt_file in os.listdir(gt):\n",
    "            gt_path = os.path.join(gt, gt_file)\n",
    "\n",
    "            #  Check if current file is an image (avoid issues with files like thumbs.db)\n",
    "            if is_image(gt_path):\n",
    "                matched = False\n",
    "                gt_name, gt_e = os.path.splitext(gt_file)\n",
    "                gt_identifier = get_variable_filename(gt_name, gt_filename_format)\n",
    "\n",
    "                if gt_identifier == None:\n",
    "                    continue\n",
    "                \n",
    "                for ori_file in os.listdir(ori):\n",
    "                    ori_path = os.path.join(ori, ori_file)\n",
    "                    ori_name, ori_e = os.path.splitext(ori_file)\n",
    "                    ori_identifier = get_variable_filename(ori_name, ori_filename_format)\n",
    "                    \n",
    "                    if ori_identifier == None:\n",
    "                        continue\n",
    "                    \n",
    "                    #  Try to find a match (original image - gt)\n",
    "                    if gt_identifier == ori_identifier:\n",
    "                        out.write(to_csv_row(ori_path, gt_path, note))\n",
    "                        i += 1\n",
    "                        matched = True\n",
    "                        break\n",
    "                \n",
    "                if not matched:\n",
    "                    print(f'No matches found for {gt_identifier}')\n",
    "            else:\n",
    "                print(f'File {gt_path} is not an image')\n",
    "        \n",
    "        print(f\"Found {i} images\")\n",
    "\n",
    "# Perform image-processing on a directory content\n",
    "# \n",
    "# Processing Pipeline example:\n",
    "#   \"png,skin=255_255_255,invert\"\n",
    "#   skin=.. Skin-based binarization rule:\n",
    "#           pixels of whatever is not skin will be set black; skin pixels will be set white\n",
    "#   bg=..   Background-based binarization rule:\n",
    "#           pixels of whatever is not background will be set white; background pixels will be set black\n",
    "#   png     Convert the image to PNG format\n",
    "# Processing operations are performed in order!\n",
    "def process_images(data_dir: str, process_pipeline: str, out_dir = '', im_filename_format: str = '') -> str:\n",
    "    #  Loop all files in the directory\n",
    "    for im_basename in os.listdir(data_dir):\n",
    "        im_path = os.path.join(data_dir, im_basename)\n",
    "        im_filename, im_e = os.path.splitext(im_basename)\n",
    "\n",
    "        #  Check if current file is an image (avoid issues with files like thumbs.db)\n",
    "        if is_image(im_path):\n",
    "            if out_dir == '':\n",
    "                out_dir = os.path.join(data_dir, 'processed')\n",
    "\n",
    "            os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "            im_identifier = get_variable_filename(im_filename, im_filename_format)\n",
    "            if im_identifier == None:\n",
    "                continue\n",
    "\n",
    "            #  Load image\n",
    "            im = cv2.imread(im_path)\n",
    "\n",
    "            #  Prepare path for out image\n",
    "            im_path = os.path.join(out_dir, im_basename)\n",
    "\n",
    "            for operation in process_pipeline.split(','):\n",
    "                #  Binarize\n",
    "                if operation.startswith('skin') or operation.startswith('bg'):\n",
    "                    #  inspired from https://stackoverflow.com/a/53989391\n",
    "                    bgr_data = operation.split('=')[1]\n",
    "                    b,g,r = [int(i) for i in bgr_data.split('_')]\n",
    "                    lower_val = (b, g, r)\n",
    "                    upper_val = lower_val\n",
    "\n",
    "                    #  If 'skin': catch only skin pixels via thresholding\n",
    "                    #  If 'bg':   catch only background pixels via thresholding\n",
    "                    mask = cv2.inRange(im, lower_val, upper_val)\n",
    "                    im = mask if operation.startswith('skin') else cv2.bitwise_not(mask)\n",
    "                #  Invert image\n",
    "                elif operation == 'invert':\n",
    "                    im = cv2.bitwise_not(im)\n",
    "                #  Convert to png\n",
    "                elif operation == 'png':\n",
    "                    im_path = os.path.join(out_dir, im_filename + '.png')\n",
    "                #  Reload image\n",
    "                elif operation == 'reload':\n",
    "                    im = cv2.imread(im_path)\n",
    "                else:\n",
    "                    print(f'Image processing operation unknown: {operation}')\n",
    "            \n",
    "            #  Save processing \n",
    "            cv2.imwrite(im_path, im)\n",
    "    return out_dir\n",
    "\n",
    "def randomize_split(csv_file: str):\n",
    "    file3c = read_csv(csv_file)\n",
    "\n",
    "    #  randomize\n",
    "    shuffle(file3c)\n",
    "\n",
    "    #  calculate splits\n",
    "    #  70% train, 15% val, 15% test\n",
    "    train_files, test_files = get_training_and_testing_sets(file3c)\n",
    "    test_files, val_files = get_training_and_testing_sets(test_files, split=.5)\n",
    "\n",
    "    #  rewrite csv file\n",
    "    with open(csv_file, 'w') as out:\n",
    "        for entry in file3c:\n",
    "            csv_fields = split_csv_fields(entry)\n",
    "\n",
    "            if entry in val_files:\n",
    "                csv_fields[2] = 'va'\n",
    "            elif entry in test_files:\n",
    "                csv_fields[2] = 'te'\n",
    "            else:\n",
    "                csv_fields[2] = 'tr'\n",
    "\n",
    "            out.write(to_csv_row(*csv_fields))\n",
    "\n",
    "def import_split(csv_file: str, single_col_file: str, outfile: str,\n",
    "                 note: str, gtf = '', orif = '', inf = '') -> None:\n",
    "    '''Import the CSV from a 1 column format split'''\n",
    "    file_content = read_csv(csv_file)\n",
    "    \n",
    "    #  Read single column file lines\n",
    "    file1c = open(single_col_file)\n",
    "    singles = file1c.read().splitlines()\n",
    "    file1c.close()\n",
    "\n",
    "    #  Create the new split file as csv\n",
    "    with open(os.path.join(outfile), 'w') as out:\n",
    "        i = 0\n",
    "        for entry in file_content: #  oriname.ext, gtname.ext, te/tr/va\n",
    "            csv_fields = split_csv_fields(entry)\n",
    "            ori_path = csv_fields[0]\n",
    "            gt_path = csv_fields[1]\n",
    "            note_old = csv_fields[2]\n",
    "            ori_name, ori_ext = os.path.splitext(os.path.basename(ori_path))\n",
    "            gt_name, gt_ext = os.path.splitext(os.path.basename(gt_path))\n",
    "\n",
    "            ori_identifier = get_variable_filename(ori_name, orif)\n",
    "            gt_identifier = get_variable_filename(gt_name, gtf)\n",
    "\n",
    "            for line in singles: #  imgname\n",
    "                line_name, line_ext = os.path.splitext(line)\n",
    "                in_identifier = get_variable_filename(line_name, inf)\n",
    "\n",
    "                if ori_identifier == in_identifier or gt_identifier == in_identifier:\n",
    "                    note_old = note\n",
    "                    i += 1\n",
    "                    print(f'Match found: {ori_identifier}\\|{gt_identifier} - {in_identifier}')\n",
    "                    break\n",
    "            \n",
    "            out.write(to_csv_row(ori_path, gt_path, note_old))\n",
    "        \n",
    "        print(f'''Converted {i}/{len(singles)} lines.\\n\n",
    "        Source file: {single_col_file}\\n\n",
    "        Target file: {outfile}''')\n",
    "\n",
    "def import_dataset(import_json: str) -> None:\n",
    "    '''Import dataset and generate metadata'''\n",
    "    if os.path.exists(import_json):\n",
    "        with open(import_json, 'r') as stream:\n",
    "            data = json.load(stream)\n",
    "\n",
    "            #  Load JSON values\n",
    "            gt = data['gt']\n",
    "            ori = data['ori']\n",
    "            root = data['root']\n",
    "            note = data['note']\n",
    "            gt_format = data['gtf']\n",
    "            ori_format = data['orif']\n",
    "            ori_process = data['oriprocess']\n",
    "            ori_process_out = data['oriprocessout']\n",
    "            gt_process = data['gtprocess']\n",
    "            gt_process_out = data['gtprocessout']\n",
    "            \n",
    "            #  Non-Defined as default note\n",
    "            if not note:\n",
    "                note = 'nd'\n",
    "            \n",
    "            #  Check if processing is required\n",
    "            if ori_process:\n",
    "                ori = process_images(ori, ori_process, ori_process_out, ori_format)\n",
    "            if gt_process:\n",
    "                gt = process_images(gt, gt_process, gt_process_out, gt_format)\n",
    "            \n",
    "            #  Analyze the dataset and create the csv files\n",
    "            analyze_dataset(gt, ori, root,\n",
    "                            note, gt_format, ori_format)\n",
    "    else:\n",
    "        print(\"JSON import file does not exist!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IKisH8MijHuN"
   },
   "source": [
    "Schmugge utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "dQUlJqmKjHuO"
   },
   "outputs": [],
   "source": [
    "def read_schmugge(skin_im_manager_path: str, images_dir: str) -> list:\n",
    "    '''From schmugge custom config (.config.SkinImManager) to a list of dict structure'''\n",
    "    sch = []\n",
    "    \n",
    "    #  images with gt errors, aa69 is also duplicated in the config file\n",
    "    blacklist = ['aa50.gt.d3.pgm', 'aa69.gt.d3.pgm', 'dd71.gt.d3.pgm', 'hh54.gt.d3.pgm']\n",
    "\n",
    "    with open(skin_im_manager_path) as f:\n",
    "        start = 0\n",
    "        i = 0\n",
    "        tmp = {}\n",
    "        for line in f:\n",
    "            blacklisted = False\n",
    "\n",
    "            #  skip first 2 lines\n",
    "            if start < 2:\n",
    "                start += 1\n",
    "                continue\n",
    "            \n",
    "            #print(f'{line}\\t{i}') #  debug\n",
    "            if line: #  line not empty\n",
    "                line = line.rstrip() #  remove End Of Line (\\n)\n",
    "\n",
    "                if i == 2: #  skin tone type\n",
    "                    skin_type = int(line)\n",
    "                    if skin_type == 0:\n",
    "                        tmp['skintone'] = 'light'\n",
    "                    elif skin_type == 1:\n",
    "                        tmp['skintone'] = 'medium'\n",
    "                    elif skin_type == 2:\n",
    "                        tmp['skintone'] = 'dark'\n",
    "                    else:\n",
    "                        tmp['skintone'] = 'nd'\n",
    "                elif i == 3: #  db type\n",
    "                    tmp['db'] = line\n",
    "                elif i == 8: #  ori\n",
    "                    tmp['ori'] = os.path.join(images_dir, line)\n",
    "                elif i == 9: #  gt\n",
    "                    tmp['gt'] = os.path.join(images_dir, line)\n",
    "                    if line in blacklist:\n",
    "                        blacklisted = True\n",
    "                \n",
    "                #  update image counter\n",
    "                i += 1\n",
    "                if i == 10: #  10 lines read, prepare for next image data\n",
    "                    if not blacklisted:\n",
    "                        sch.append(tmp)\n",
    "                    tmp = {}\n",
    "                    i = 0\n",
    "    \n",
    "    print(f'Schmugge custom config read correctly, found {len(sch)} images')\n",
    "    return sch\n",
    "\n",
    "def process_schmugge(sch: list, outfile: str, train = 70, test = 15, val = 15,\n",
    "                     ori_out_dir = 'new_ori', gt_out_dir = 'new_gt'):\n",
    "    '''From schmugge list of dicts structure to csv file and processed images'''\n",
    "    #  Prepare new ori and gt dirs\n",
    "    os.makedirs(ori_out_dir, exist_ok=True)\n",
    "    os.makedirs(gt_out_dir, exist_ok=True)\n",
    "\n",
    "    with open(outfile, 'w') as out:\n",
    "        #  Randomize\n",
    "        shuffle(sch)\n",
    "\n",
    "        #  70% train, 15% val, 15% test\n",
    "        train_files, test_files = get_training_and_testing_sets(sch)\n",
    "        test_files, val_files = get_training_and_testing_sets(test_files, split=.5)\n",
    "\n",
    "        for entry in sch:\n",
    "            db = int(entry['db'])\n",
    "            ori_path = entry['ori']\n",
    "            gt_path = entry['gt']\n",
    "            \n",
    "            ori_basename = os.path.basename(ori_path)\n",
    "            gt_basename = os.path.basename(gt_path)\n",
    "            ori_filename, ori_e = os.path.splitext(ori_basename)\n",
    "            gt_filename, gt_e = os.path.splitext(gt_basename)\n",
    "\n",
    "            #  Process images\n",
    "            \n",
    "            #  load images\n",
    "            ori_im = cv2.imread(ori_path)\n",
    "            gt_im = cv2.imread(gt_path)\n",
    "            #  png\n",
    "            ori_out = os.path.join(ori_out_dir, ori_filename + '.png')\n",
    "            gt_out = os.path.join(gt_out_dir, gt_filename + '.png')\n",
    "            #  binarize gt: whatever isn't background, is skin\n",
    "            if db == 4 or db == 3: #  Uchile/UW: white background\n",
    "                b = 255\n",
    "                g = 255\n",
    "                r = 255\n",
    "                lower_val = (b, g, r)\n",
    "                upper_val = lower_val\n",
    "                #  Threshold the image to get only selected colors\n",
    "                mask = cv2.inRange(gt_im, lower_val, upper_val)\n",
    "                #cv2_imshow(mask) #  debug\n",
    "                #  what isn't bg is white\n",
    "                sk = cv2.bitwise_not(mask)\n",
    "                gt_im = sk\n",
    "            else: #  background = 180,180,180\n",
    "                b = 180\n",
    "                g = 180\n",
    "                r = 180\n",
    "                lower_val = (b, g, r)\n",
    "                upper_val = lower_val\n",
    "                #  Threshold the image to get only selected colors\n",
    "                mask = cv2.inRange(gt_im, lower_val, upper_val)\n",
    "                #cv2_imshow(mask) #  debug\n",
    "                #  what isn't bg is white\n",
    "                sk = cv2.bitwise_not(mask)\n",
    "                gt_im = sk\n",
    "            \n",
    "            #  Save processing \n",
    "            cv2.imwrite(ori_out, ori_im)\n",
    "            cv2.imwrite(gt_out, gt_im)\n",
    "\n",
    "            skintone = entry['skintone']\n",
    "            note = 'te'\n",
    "            if entry in train_files:\n",
    "                note = 'tr'\n",
    "            elif entry in val_files:\n",
    "                note = 'va'\n",
    "            \n",
    "            out.write(to_csv_row(ori_out, gt_out, note, skintone))\n",
    "\n",
    "def csv_skintone_filter(csv_file: str, skintone: str, mode = 'train', val_percent = .15, test_percent = .15):\n",
    "    '''Generate random splits for the given skintone. Overwrite Schmugge CSV file'''\n",
    "    #  read the images CSV\n",
    "    file3c = read_csv(csv_file)\n",
    "\n",
    "    #  randomize\n",
    "    shuffle(file3c)\n",
    "\n",
    "    #  calculate splits length\n",
    "    totalsk = csv_skintone_count(csv_file, skintone) #  total items to train/val/test on\n",
    "    totalva = round(totalsk * val_percent)\n",
    "    totalte = round(totalsk * test_percent)\n",
    "    jva = 0\n",
    "    jte = 0\n",
    "\n",
    "    #  rewrite csv file\n",
    "    with open(csv_file, 'w') as out:\n",
    "        for entry in file3c:\n",
    "            csv_fields = split_csv_fields(entry)\n",
    "            ori_path = csv_fields[0]\n",
    "            gt_path = csv_fields[1]\n",
    "            skint = csv_fields[3]\n",
    "\n",
    "            if skint != skintone: #  should not be filtered\n",
    "                note = 'nd'\n",
    "            else: #  should be in the filter\n",
    "                if mode == 'train': #  if it is a training filter\n",
    "                    if jva < totalva: #  there are still places left to be in validation set\n",
    "                        note = 'va'\n",
    "                        jva += 1\n",
    "                    elif jte < totalte: #  there are still places left to be in test set\n",
    "                        note = 'te'\n",
    "                        jte += 1\n",
    "                    else: #  no more validation places to sit in, go in train set\n",
    "                        note = 'tr'\n",
    "                else: #  if it is a testing filter, just place them all in test set\n",
    "                    note = 'te'\n",
    "            out.write(to_csv_row(ori_path, gt_path, note, skint))\n",
    "\n",
    "def csv_skintone_count(csv_file: str, skintone: str):\n",
    "    '''Print the total amount of items of the given skintone'''\n",
    "    data = match_rows(csv_file, (skintone), 3)\n",
    "    data_len = len(data)\n",
    "    # print('\\n'.join(data))  #  debug\n",
    "    print(f\"Found {data_len} items of type {skintone}\")\n",
    "    return data_len\n",
    "\n",
    "def csv_note_count(csv_file: str, mode: str):\n",
    "    '''Print the total amount of items of the given mode; \"train\" mode also includes validation'''\n",
    "    targets = ('tr', 'va') if mode == 'train' else ('te')\n",
    "    data = match_rows(csv_file, (targets), 2)\n",
    "    data_len = len(data)\n",
    "    # print('\\n'.join(data))  #  debug\n",
    "    print(f\"Found {data_len} items of type {' '.join(targets)}\")\n",
    "    return data_len\n",
    "\n",
    "def gen_sch_by_skintone(skintone: str, mode: str):\n",
    "    '''\n",
    "    Re-import and re-process Schmugge, and generate random splits for the given skintone\n",
    "    \n",
    "    mode can either be \"train\" or \"test\"\n",
    "    \n",
    "    eg. usage:\n",
    "    gen_sch_by_skintone('dark', 'train')\n",
    "    gen_sch_by_skintone('light', 'train')\n",
    "    gen_sch_by_skintone('medium', 'test')\n",
    "    '''\n",
    "    sch_csv = 'dataset/Schmugge/data.csv'\n",
    "\n",
    "    #  re-import Schmugge\n",
    "    schm = read_schmugge('dataset/Schmugge/data/.config.SkinImManager', 'dataset/Schmugge/data/data')\n",
    "    process_schmugge(schm, sch_csv, ori_out_dir='dataset/Schmugge/newdata/ori', gt_out_dir='dataset/Schmugge/newdata/gt')\n",
    "\n",
    "    csv_skintone_filter(sch_csv, skintone, mode = mode)\n",
    "    csv_skintone_count(sch_csv, skintone)\n",
    "    csv_note_count(sch_csv, mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "erTLO_gPjHuP"
   },
   "source": [
    "<a name=\"Generate-Datasets-CSV-Metadata\"></a>\n",
    "### Generate Datasets CSV Metadata\n",
    "[[Return to ToC]](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cUJHgu5IJJxv",
    "outputId": "510a31d9-baf5-43da-f6d5-c85d8e750d84"
   },
   "outputs": [],
   "source": [
    "#  ECU has no native splits; Skinny splits will be used as default\n",
    "if 'ecu' in to_import:\n",
    "    import_dataset(\"dataset/import_ecu.json\")\n",
    "\n",
    "#  Uchile has no native splits; randomize\n",
    "if 'uchile' in to_import:\n",
    "    import_dataset(\"dataset/import_uchile.json\")\n",
    "    randomize_split('dataset/Pratheepan/data.csv')\n",
    "\n",
    "#  HGR is composed of 3 sub datasets\n",
    "#  has no native splits; mine will be used as default\n",
    "if 'hgr' in to_import:\n",
    "    import_dataset(\"dataset/import_hgr1.json\")\n",
    "    import_dataset(\"dataset/import_hgr2a.json\")\n",
    "    import_dataset(\"dataset/import_hgr2b.json\")\n",
    "\n",
    "#  Pratheepan is composed of 2 sub datasets\n",
    "#  but has no native splits; randomize\n",
    "if 'pratheepan' in to_import:\n",
    "    import_dataset(\"dataset/import_pratheepanface.json\")\n",
    "    import_dataset(\"dataset/import_pratheepanfamily.json\")\n",
    "    randomize_split('dataset/Pratheepan/data.csv')\n",
    "\n",
    "#  abd has native train/test splits\n",
    "if 'abd' in to_import:\n",
    "    import_dataset(\"dataset/import_abd_te.json\")\n",
    "    import_dataset(\"dataset/import_abd_tr.json\")\n",
    "\n",
    "#  VPU is composed of 5 sub datasets with native train/test splits\n",
    "if 'vpu' in to_import:\n",
    "    import_dataset(\"dataset/import_ami_te.json\")\n",
    "    import_dataset(\"dataset/import_ami_tr.json\")\n",
    "    import_dataset(\"dataset/import_ed_te.json\")\n",
    "    import_dataset(\"dataset/import_ed_tr.json\")\n",
    "    import_dataset(\"dataset/import_liris_te.json\")\n",
    "    import_dataset(\"dataset/import_liris_tr.json\")\n",
    "    import_dataset(\"dataset/import_ssg_te.json\")\n",
    "    import_dataset(\"dataset/import_ssg_tr.json\")\n",
    "    import_dataset(\"dataset/import_ut_te.json\")\n",
    "    import_dataset(\"dataset/import_ut_tr.json\")\n",
    "\n",
    "#  Schmugge has really diverse filename formats but has a custom data manager file included\n",
    "#  has no native splits; mine will be used as default\n",
    "if 'schmugge' in to_import:\n",
    "    schm = read_schmugge('dataset/Schmugge/data/.config.SkinImManager', 'dataset/Schmugge/data/data')\n",
    "    process_schmugge(schm, 'dataset/Schmugge/data.csv',\n",
    "                     ori_out_dir='dataset/Schmugge/newdata/ori', gt_out_dir='dataset/Schmugge/newdata/gt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l_hDPvMqQR2B"
   },
   "source": [
    "Import Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uBnIeju53obQ",
    "outputId": "9f9beddd-9310-41b3-94ea-ba5373044917"
   },
   "outputs": [],
   "source": [
    "# Import ECU splits from the Skinny paper\n",
    "\n",
    "# unzip archive\n",
    "!unzip -j drive/MyDrive/datasets/sets/ECU_Skinny.zip -d dataset/ECU/\n",
    "\n",
    "# import splits\n",
    "import_split('dataset/ECU/data.csv', 'dataset/ECU/train.txt',\n",
    "             'dataset/ECU/data.csv', 'tr')\n",
    "import_split('dataset/ECU/data.csv', 'dataset/ECU/test.txt',\n",
    "            'dataset/ECU/data.csv', 'te')\n",
    "import_split('dataset/ECU/data.csv', 'dataset/ECU/val.txt',\n",
    "            'dataset/ECU/data.csv', 'va')\n",
    "\n",
    "\n",
    "# Import my HGR and Schmugge splits\n",
    "sch_from = 'drive/MyDrive/training/skinny/checkpoint-20210505-225202/schmugge_datacsv_model.csv'\n",
    "hgr_from = 'drive/MyDrive/training/skinny/checkpoint-20210512-220723/HGR_data.csv'\n",
    "sch_to = 'dataset/Schmugge/data.csv'\n",
    "hgr_to = 'dataset/HGR_small/data.csv'\n",
    "\n",
    "!rm $sch_to\n",
    "!rm $hgr_to\n",
    "\n",
    "!cp $sch_from $sch_to\n",
    "!cp $hgr_from $hgr_to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mvLdOkThjHuQ"
   },
   "source": [
    "<a name=\"Define-Skin-Detector\"></a>\n",
    "# Define Skin Detector\n",
    "[[Return to ToC]](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zqh6khEOjHuQ"
   },
   "source": [
    "<a name=\"Architecture\"></a>\n",
    "### Architecture\n",
    "[[Return to ToC]](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q3jX-C5Guqa0"
   },
   "source": [
    "Python Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "nQOz5t8rurx3"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from abc import abstractmethod\n",
    "from xml.etree import ElementTree as ET\n",
    "from typing import Callable, Any\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "import json\n",
    "\n",
    "from google.colab.patches import cv2_imshow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7aTkPRWSusO6"
   },
   "source": [
    "Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "4n7IBE2busaS"
   },
   "outputs": [],
   "source": [
    "def inception_module(prev_layer, filters: int, activation=layers.LeakyReLU):\n",
    "    filters = filters // 4\n",
    "    conv_1 = layers.Conv2D(filters, (1, 1), padding='same')(prev_layer)\n",
    "    conv_1 = activation()(conv_1)\n",
    "    conv_3 = layers.Conv2D(filters, (1, 1), padding='same')(prev_layer)\n",
    "    conv_3 = layers.Conv2D(filters, (3, 3), padding='same')(conv_3)\n",
    "    conv_3 = activation()(conv_3)\n",
    "    conv_5 = layers.Conv2D(filters, (1, 1), padding='same')(prev_layer)\n",
    "    conv_5 = layers.Conv2D(filters, (5, 5), padding='same')(conv_5)\n",
    "    conv_5 = activation()(conv_5)\n",
    "    max_pool = layers.MaxPool2D(padding='same', strides=(1, 1))(prev_layer)\n",
    "    max_pool = layers.Conv2D(filters, (1, 1), padding='same')(max_pool)\n",
    "    max_pool = activation()(max_pool)\n",
    "    return tf.concat([conv_1, conv_3, conv_5, max_pool], axis=-1)\n",
    "\n",
    "def dense_block(prev_layer, filters: int, kernel_size: int or tuple, activation=layers.LeakyReLU):\n",
    "    dense_1 = layers.Conv2D(filters // 2, kernel_size, padding='same')(prev_layer)\n",
    "    dense_1 = layers.BatchNormalization()(dense_1)\n",
    "    dense_1 = activation()(dense_1)\n",
    "    dense_2 = layers.Conv2D(filters // 4, kernel_size, padding='same')(dense_1)\n",
    "    dense_2 = layers.BatchNormalization()(dense_2)\n",
    "    dense_2 = activation()(dense_2)\n",
    "    dense_3 = layers.Conv2D(filters // 8, kernel_size, padding='same')(dense_2)\n",
    "    dense_3 = layers.BatchNormalization()(dense_3)\n",
    "    dense_3 = activation()(dense_3)\n",
    "    return tf.concat([dense_1, dense_2, dense_3, prev_layer], axis=-1)\n",
    "\n",
    "def get_filters_count(level: int, initial_filters: int) -> int:\n",
    "    return 2**(level-1)*initial_filters\n",
    "\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, levels: int = None, initial_filters: int = None,\n",
    "                 image_channels: int = None, log_dir: str = 'logs',\n",
    "                 load_checkpoint: bool = False, checkpoint_extension: str = 'ckpt',\n",
    "                 model_name: str = None) -> None:\n",
    "        self.levels = levels\n",
    "        self.initial_filters = initial_filters\n",
    "        self.image_channels = image_channels\n",
    "        self.keras_model = None\n",
    "        self.log_dir = log_dir\n",
    "        self.checkpoint_extension = checkpoint_extension\n",
    "        if model_name is not None:\n",
    "            self.name = model_name\n",
    "        self.load_checkpoint = load_checkpoint\n",
    "        if not load_checkpoint and os.path.isdir(self.get_logdir()):\n",
    "            self.name = f\"{self.name}_{get_timestamp()}\"\n",
    "\n",
    "    def get_model(self) -> keras.Model:\n",
    "        path = os.path.join(self.log_dir, self.name, 'checkpoint', f'saved_model.{self.checkpoint_extension}')\n",
    "        \n",
    "        if self.load_checkpoint and self.checkpoint_extension != 'ckpt': #  load full model\n",
    "            self.keras_model = load_model(path, compile=False)\n",
    "            return self.keras_model\n",
    "\n",
    "        self.keras_model = self.create_model()\n",
    "        self.__change_model_name()\n",
    "        self.__plot_model(self.keras_model)\n",
    "\n",
    "        if self.load_checkpoint: #  load weights\n",
    "            try:\n",
    "                self.keras_model.load_weights(path)\n",
    "            except Exception as e:\n",
    "                raise e\n",
    "        return self.keras_model\n",
    "\n",
    "    def __plot_model(self, model: keras.Model) -> None:\n",
    "        plot_model(model, to_file=os.path.join(self.log_dir, self.name, 'model.png'), show_shapes=True)\n",
    "\n",
    "    def __change_model_name(self) -> None:\n",
    "        if self.name is not None and self.keras_model is not None:\n",
    "            self.keras_model._name = self.name\n",
    "\n",
    "    def get_logdir(self) -> str:\n",
    "        return os.path.join(self.log_dir, self.name)\n",
    "\n",
    "    @abstractmethod\n",
    "    def create_model(self) -> keras.Model:\n",
    "        pass\n",
    "\n",
    "\n",
    "class Skinny(Model):\n",
    "    name = \"Skinny\"\n",
    "\n",
    "    def create_model(self) -> keras.Model:\n",
    "        self.levels += 1\n",
    "        kernel_size = (3, 3)\n",
    "        layers_list = [None for _ in range(self.levels)]\n",
    "        layers_list[0] = layers.Input(shape=(None, None, self.image_channels), name='feature')\n",
    "        activation = layers.LeakyReLU\n",
    "\n",
    "        for i in range(1, self.levels):\n",
    "            filters = get_filters_count(i, self.initial_filters)\n",
    "            prev = i-1\n",
    "            if i != 1:\n",
    "                layers_list[i] = layers.MaxPool2D()(layers_list[prev])\n",
    "                prev = i\n",
    "\n",
    "            layers_list[i] = layers.Conv2D(filters, kernel_size, padding='same')(layers_list[prev])\n",
    "            layers_list[i] = layers.BatchNormalization()(layers_list[i])\n",
    "            layers_list[i] = activation()(layers_list[i])\n",
    "            layers_list[i] = inception_module(layers_list[i], filters, activation)\n",
    "\n",
    "        for i in range(self.levels-2, 0, -1):\n",
    "            filters = get_filters_count(i, self.initial_filters)\n",
    "            layers_list[i+1] = layers.UpSampling2D()(layers_list[i+1])\n",
    "            layers_list[i+1] = layers.Conv2D(filters, kernel_size, padding='same')(layers_list[i+1])\n",
    "            layers_list[i+1] = layers.BatchNormalization()(layers_list[i+1])\n",
    "            layers_list[i+1] = activation()(layers_list[i+1])\n",
    "\n",
    "            layers_list[i] = dense_block(layers_list[i], filters, kernel_size, activation)\n",
    "\n",
    "            layers_list[i] = tf.concat([layers_list[i+1], layers_list[i]], axis=-1)\n",
    "            layers_list[i] = inception_module(layers_list[i], filters, activation)\n",
    "\n",
    "        layers_list[1] = layers.Conv2D(self.initial_filters, kernel_size, padding='same')(layers_list[1])\n",
    "        layers_list[1] = activation()(layers_list[1])\n",
    "        layers_list[1] = layers.Conv2D(self.initial_filters//2, kernel_size, padding='same')(layers_list[1])\n",
    "        layers_list[1] = activation()(layers_list[1])\n",
    "        layers_list[1] = layers.Conv2D(1, kernel_size, padding='same',\n",
    "                                       activation='sigmoid', name='label')(layers_list[1])\n",
    "\n",
    "        model = keras.Model(inputs=[layers_list[0]], outputs=[layers_list[1]], name=self.name)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yr_qjZfqvErA"
   },
   "source": [
    "Define PreProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "3qZV2BhqvE6m"
   },
   "outputs": [],
   "source": [
    "class Preprocessor:\n",
    "    def __init__(self):\n",
    "        self.operations = [] #  Preprocessor has no operations by default\n",
    "    \n",
    "    def downscale(self, max_pixel_count):\n",
    "        '''Add a downscale operation to the preprocessing list of operations. Return self'''\n",
    "        def downscale_operation(data):\n",
    "            '''Downscale the images composed of more pixels than max_pixel_count preserving the aspect ratio'''\n",
    "            for k, v in data.items():\n",
    "                tensor_shape = tf.cast(tf.shape(v), tf.float32)\n",
    "                coefficient = max_pixel_count / (tensor_shape[0] * tensor_shape[1])\n",
    "                coefficient = tf.math.sqrt(coefficient)\n",
    "                data[k] = tf.cond(coefficient >= 1.0, lambda: v,\n",
    "                                  lambda: tf.image.resize(v, [tf.cast(tensor_shape[0] * coefficient, tf.uint16),\n",
    "                                                              tf.cast(tensor_shape[1] * coefficient, tf.uint16)]))\n",
    "            return data\n",
    "\n",
    "        self.operations.append(downscale_operation)\n",
    "        return self\n",
    "    \n",
    "    def cast(self, dtype):\n",
    "        '''Add a cast operation to the preprocessing list of operations. Return self'''\n",
    "        def cast_operation(data):\n",
    "            '''Cast the images data into the given dtype'''\n",
    "            for k, v in data.items():\n",
    "                data[k] = tf.cast(v, dtype)\n",
    "            return data\n",
    "\n",
    "        self.operations.append(cast_operation)\n",
    "        return self\n",
    "    \n",
    "    def normalize(self):\n",
    "        '''Add a normalize operation to the preprocessing list of operations. Return self'''\n",
    "        def normalize_operation(data):\n",
    "            '''Transform the images data from uint8(range 0-255) into floats(range 0-1)'''\n",
    "            for k, v in data.items():\n",
    "                data[k] = v / 255.0\n",
    "            return data\n",
    "\n",
    "        self.operations.append(normalize_operation)\n",
    "        return self\n",
    "    \n",
    "    def pad(self, network_levels):\n",
    "        '''Add a padding operation to the preprocessing list of operations. Return self'''\n",
    "        number_multiple = 2**(network_levels-1)\n",
    "        def padding_operation(data):\n",
    "            '''Add padding to the bottom and right sides of the images'''\n",
    "            for k, v in data.items():\n",
    "                tensor_shape = tf.shape(v)\n",
    "                data[k] = tf.pad(v, [[0, number_multiple - tensor_shape[0] % number_multiple],\n",
    "                                     [0,  number_multiple - tensor_shape[1] % number_multiple],\n",
    "                                     [0, 0]])\n",
    "            return data\n",
    "\n",
    "        self.operations.append(padding_operation)\n",
    "        return self\n",
    "    \n",
    "    def add_to_graph(self, dataset) -> tf.data.Dataset:\n",
    "        '''\n",
    "        Execute all the operation functions defined in the Preprocessor instance\n",
    "        on the given Dataset object.\n",
    "        Return the transformed Dataset object\n",
    "        '''\n",
    "        for operation in self.operations:\n",
    "            dataset = dataset.map(operation) #  map apply one function on every element of the Dataset\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vBucaN-ovFF-"
   },
   "source": [
    "Define DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6jbs21davFLt"
   },
   "outputs": [],
   "source": [
    "class DataLoader(object):\n",
    "    buffer_size = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "    def __init__(self, dataset_dir: str, batch_size: int, preprocessor: Preprocessor = None):\n",
    "        self.dataset_dir = dataset_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.val_dataset = None\n",
    "        self.train_dataset = None\n",
    "        self.test_dataset = None\n",
    "        self.preprocessor = Preprocessor() if preprocessor is None else preprocessor\n",
    "\n",
    "    @property\n",
    "    def train_dataset(self):\n",
    "        return self.__batch_and_prefetch(self.__train_dataset)\n",
    "\n",
    "    @train_dataset.setter\n",
    "    def train_dataset(self, dataset: tf.data.Dataset):\n",
    "        self.__train_dataset = dataset\n",
    "\n",
    "    @property\n",
    "    def test_dataset(self):\n",
    "        return self.__batch_and_prefetch(self.__test_dataset)\n",
    "\n",
    "    @test_dataset.setter\n",
    "    def test_dataset(self, dataset: tf.data.Dataset):\n",
    "        self.__test_dataset = dataset\n",
    "\n",
    "    @property\n",
    "    def val_dataset(self):\n",
    "        return self.__batch_and_prefetch(self.__val_dataset)\n",
    "\n",
    "    @val_dataset.setter\n",
    "    def val_dataset(self, dataset: tf.data.Dataset):\n",
    "        self.__val_dataset = dataset\n",
    "\n",
    "    @property\n",
    "    def preprocessor(self) -> Preprocessor:\n",
    "        return self.__preprocessor\n",
    "\n",
    "    @preprocessor.setter\n",
    "    def preprocessor(self, preprocessor: Preprocessor):\n",
    "        self.__preprocessor = preprocessor\n",
    "        self.__reinstantiate()\n",
    "\n",
    "    def __reinstantiate(self):\n",
    "        self.train_dataset = self.__create_dataset_pipeline('tr')\n",
    "        self.val_dataset = self.__create_dataset_pipeline('va', shuffle=False)\n",
    "        self.test_dataset = self.__create_dataset_pipeline('te', shuffle=False)\n",
    "\n",
    "    def __batch_and_prefetch(self, dataset: tf.data.Dataset) -> tf.data.Dataset:\n",
    "        return dataset.\\\n",
    "            padded_batch(self.batch_size, padded_shapes=({'feature': [None, None, 3]}, {'label': [None, None, 1]})).\\\n",
    "            prefetch(buffer_size=self.buffer_size)\n",
    "    \n",
    "    def __get_subset_paths(self, subset: str) -> list:\n",
    "        # Read the images CSV (ori_image_filename.ext, gt_image_filename.ext)\n",
    "        file = open(os.path.join(self.dataset_dir, 'data.csv'))\n",
    "        file3c = file.read().splitlines()\n",
    "        file.close()\n",
    "        files = []\n",
    "\n",
    "        for entry in file3c:\n",
    "            csv_fields = split_csv_fields(entry)\n",
    "            ori_path = csv_fields[0]\n",
    "            gt_path = csv_fields[1]\n",
    "            note = csv_fields[2]\n",
    "            \n",
    "            if note == subset:\n",
    "                files.append((ori_path, gt_path))\n",
    "        \n",
    "        if len(files) == 0:\n",
    "            print(f'''No files found for subset {subset}!\\n\n",
    "            using the whole dataset instead''')\n",
    "            for entry in file3c:\n",
    "                csv_fields = split_csv_fields(entry)\n",
    "                ori_path = csv_fields[0]\n",
    "                gt_path = csv_fields[1]\n",
    "                \n",
    "                files.append((ori_path, gt_path))\n",
    "        else:\n",
    "            print(f'Found {subset} split of {len(files)} files')\n",
    "        \n",
    "        return files\n",
    "\n",
    "    def __create_dataset_pipeline(self, subset: str, shuffle: bool = True) -> tf.data.Dataset:\n",
    "        def process_example_paths(example):\n",
    "            return {'feature': tf.io.decode_image(tf.io.read_file(example[0]), channels=3, expand_animations = False),\n",
    "                    'label': tf.io.decode_image(tf.io.read_file(example[1]), channels=1,  expand_animations = False)}\n",
    "\n",
    "        def convert_to_in_out_dicts(example):\n",
    "            output_dict = {'label': example.pop('label')}\n",
    "            return example, output_dict\n",
    "\n",
    "        dataset = self.__get_subset_paths(subset)\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(dataset)\n",
    "        dataset = dataset.map(process_example_paths)\n",
    "        dataset = self.preprocessor.add_to_graph(dataset)\n",
    "        dataset = dataset.map(convert_to_in_out_dicts).cache()\n",
    "        if shuffle:\n",
    "            dataset = dataset.shuffle(2000, reshuffle_each_iteration=True)\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "KlOJNVGduUSZ"
   },
   "outputs": [],
   "source": [
    "#  Custom loader used for predictions\n",
    "\n",
    "\n",
    "def my_batch(dataset: tf.data.Dataset, batch_size) -> tf.data.Dataset:\n",
    "    return dataset.\\\n",
    "        padded_batch(batch_size, padded_shapes=({'feature': [None, None, 3]})).\\\n",
    "        prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "def my_file(path: str) -> list:\n",
    "    files = [path]\n",
    "    return files\n",
    "\n",
    "def my_loader(path, preprocessor) -> tf.data.Dataset:\n",
    "    def my_process(example):\n",
    "        return {'feature': tf.io.decode_image(tf.io.read_file(example), channels=3, expand_animations = False)}\n",
    "\n",
    "    dataset = my_file(path)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(dataset)\n",
    "    dataset = dataset.map(my_process)\n",
    "\n",
    "    t_start = time.time()\n",
    "    #  preprocessing\n",
    "    dataset = preprocessor.add_to_graph(dataset)\n",
    "    t_elapsed = time.time() - t_start\n",
    "\n",
    "    dataset = dataset.cache()\n",
    "    return dataset, t_elapsed\n",
    "\n",
    "def single_predict(model, im_path: str, out_path: str, preprocessor):\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok = True)\n",
    "\n",
    "    #  Get tf Dataset structure containing the image to predict and elapsed preprocessing time\n",
    "    tf_ds, t_elapsed_pre = my_loader(im_path, preprocessor)\n",
    "\n",
    "    #  Predict the image\n",
    "    for entry in tf_ds:\n",
    "        #  Convert to tensor to prevent memory leak https://stackoverflow.com/a/64765018\n",
    "        tensor = tf.convert_to_tensor(entry['feature'], dtype=tf.float32)\n",
    "        tensor = tf.expand_dims(tensor, axis=0) #  add a dimension\n",
    "\n",
    "        model.get_model()\n",
    "\n",
    "        #  Get time before prediction\n",
    "        t_start = time.time()\n",
    "\n",
    "        #  Predict from feature image (X)\n",
    "        pred = model.keras_model.predict(tensor)\n",
    "        #  post-processing\n",
    "        pred = pred[0]*255 #  reshape and de-preprocess\n",
    "        \n",
    "        #  prediction + postprocessing\n",
    "        t_elapsed = time.time() - t_start\n",
    "        #  preprocessing + prediction + postprocessing elapsed time\n",
    "        t_elapsed_full = t_elapsed_pre + t_elapsed\n",
    "\n",
    "        # Save to a file\n",
    "        cv2.imwrite(out_path, pred)\n",
    "\n",
    "        print(t_elapsed_pre)\n",
    "        print(t_elapsed)\n",
    "        print(t_elapsed_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gf0u4as4vpTs"
   },
   "source": [
    "Define Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "A2ehVveyvpbB"
   },
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "\n",
    "    def __init__(self, data_loader: DataLoader, model: Model,\n",
    "                 log_dir: str = './logs', evaluate_test_data=False):\n",
    "        self.data_loader = data_loader\n",
    "        self.model = model\n",
    "        self.metrics = []\n",
    "        self.losses = []\n",
    "        self.callbacks = []\n",
    "        self.log_dir = os.path.join(log_dir, model.name)\n",
    "        self.timelog = None\n",
    "        self.evaluate_test_data = evaluate_test_data\n",
    "\n",
    "    @property\n",
    "    def model(self) -> Model:\n",
    "        return self.__model\n",
    "\n",
    "    @model.setter\n",
    "    def model(self, model: Model):\n",
    "        self.__model = model\n",
    "\n",
    "    @property\n",
    "    def data_loader(self) -> DataLoader:\n",
    "        return self.__data_loader\n",
    "\n",
    "    @data_loader.setter\n",
    "    def data_loader(self, data_loader: DataLoader):\n",
    "        self.__data_loader = data_loader\n",
    "\n",
    "    def add_metrics(self, metrics):\n",
    "        if type(metrics) is not list:\n",
    "            metrics = [metrics]\n",
    "        for metric in metrics:\n",
    "            self.metrics.append(metric)\n",
    "\n",
    "    def add_losses(self, losses) -> None:\n",
    "        if type(losses) is not list:\n",
    "            losses = [losses]\n",
    "        for loss in losses:\n",
    "            self.losses.append(loss)\n",
    "\n",
    "    def add_callbacks(self, callbacks) -> None:\n",
    "        if type(callbacks) is not list:\n",
    "            callbacks = [callbacks]\n",
    "        for callback in callbacks:\n",
    "            self.callbacks.append(callback)\n",
    "\n",
    "    def combined_loss(self):\n",
    "        def loss(y_true, y_pred):\n",
    "            result = None\n",
    "            for i, v in enumerate(self.losses):\n",
    "                if i == 0:\n",
    "                    result = v(y_true, y_pred)\n",
    "                else:\n",
    "                    result += v(y_true, y_pred)\n",
    "            return result\n",
    "        return loss\n",
    "\n",
    "    def __log_evaluation_metrics(self, metrics: dict):\n",
    "        root = ET.Element('metrics')\n",
    "        tree = ET.ElementTree(root)\n",
    "        for name, value in metrics.items():\n",
    "            metric_element = ET.SubElement(root, name)\n",
    "            metric_element.text = str(value)\n",
    "        tree.write(open(os.path.join(self.model.get_logdir(), 'test_metrics.xml'), 'w'), encoding='unicode')\n",
    "\n",
    "    def train(self, epochs, optimizer, initial_epoch=0, verbose=1):\n",
    "        assert self.model is not None, \"Model hasn't been set for the trainer.\"\n",
    "        assert self.data_loader is not None, \"DataLoader hasn't been set for the trainer.\"\n",
    "        os.makedirs(self.model.get_logdir(), exist_ok=True)\n",
    "        model = self.model.get_model()\n",
    "        model.compile(optimizer=optimizer, loss=self.combined_loss(), metrics=self.metrics)\n",
    "\n",
    "        model.fit(self.data_loader.train_dataset, validation_data=self.data_loader.val_dataset,\n",
    "                  epochs=epochs, verbose=verbose, initial_epoch=initial_epoch,\n",
    "                  callbacks=self.callbacks, shuffle=True)\n",
    "        if self.evaluate_test_data:\n",
    "            evaluation_metrics = model.evaluate(self.data_loader.test_dataset, verbose=1)\n",
    "            evaluation_metrics = dict(zip(model.metrics_names, evaluation_metrics))\n",
    "            self.__log_evaluation_metrics(evaluation_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6pap7Ajyvpg3"
   },
   "source": [
    "Define WorkScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "_IdmW9BBvplP"
   },
   "outputs": [],
   "source": [
    "class WorkScheduler:\n",
    "    def __init__(self) -> None:\n",
    "        self.data = []\n",
    "\n",
    "    def add_data(self, model: Model,\n",
    "                 func: Callable[[Model, Any], None],\n",
    "                 **kwargs) -> None:\n",
    "        self.data.append((model, func, kwargs))\n",
    "\n",
    "    def do_work(self) -> None:\n",
    "        for model, func, kwargs in self.data:\n",
    "            tf.keras.backend.clear_session()\n",
    "            tf.compat.v1.reset_default_graph()\n",
    "            func(model=model, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hfzWKQCiv4bW"
   },
   "source": [
    "Define losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "orSZWReTv4ki"
   },
   "outputs": [],
   "source": [
    "def dice_loss(y_true, y_pred, epsilon=1e-15):\n",
    "    numerator = 2 * tf.reduce_sum(y_true * y_pred, axis=(1, 2, 3))\n",
    "    denominator = tf.reduce_sum(y_true + y_pred, axis=(1, 2, 3))\n",
    "    loss = tf.squeeze(tf.reshape(1 - numerator / denominator, (-1, 1, 1)))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ovs--81wa5V"
   },
   "source": [
    "Define metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "GI9TWN8Uwa_R"
   },
   "outputs": [],
   "source": [
    "def recall(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall_score = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall_score\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision_score = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision_score\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    precision_score = precision(y_true, y_pred)\n",
    "    recall_score = recall(y_true, y_pred)\n",
    "    return 2 * ((precision_score * recall_score) / (precision_score + recall_score + K.epsilon()))\n",
    "\n",
    "def iou(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    intersection = y_true * y_pred\n",
    "    not_true = 1 - y_true\n",
    "    union = y_true + (not_true * y_pred)\n",
    "\n",
    "    return (K.sum(intersection, axis=-1) + K.epsilon()) / (K.sum(union, axis=-1) + K.epsilon())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nIUBDDWbwbJm"
   },
   "source": [
    "Define callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "7eVAaUSPwbNf"
   },
   "outputs": [],
   "source": [
    "class CustomCallback(keras.callbacks.Callback):\n",
    "    pass\n",
    "\n",
    "class ModelCheckpoint(keras.callbacks.ModelCheckpoint, CustomCallback):\n",
    "    checkpoint_name = 'saved_model.ckpt'\n",
    "\n",
    "    def set_model(self, model):\n",
    "        dir_name = os.path.join(self.filepath, 'checkpoint')\n",
    "        os.makedirs(dir_name, exist_ok=True)\n",
    "        timestr = get_timestamp()\n",
    "        self.filepath = os.path.join(F\"/content/drive/MyDrive/training/skinny/checkpoint-\" + timestr, self.checkpoint_name )\n",
    "        #self.filepath = os.path.join(F\"/content/drive/MyDrive/training/skinny/dark/checkpoint-\" + timestr, self.checkpoint_name )\n",
    "        super().set_model(model)\n",
    "\n",
    "class ReduceLROnPlateau(keras.callbacks.ReduceLROnPlateau, CustomCallback):\n",
    "    pass\n",
    "\n",
    "class ProgbarLogger(keras.callbacks.ProgbarLogger, CustomCallback):\n",
    "    pass\n",
    "\n",
    "class EarlyStopping(keras.callbacks.EarlyStopping, CustomCallback):\n",
    "    pass\n",
    "\n",
    "class TensorBoard(keras.callbacks.TensorBoard, CustomCallback):\n",
    "    def set_model(self, model):\n",
    "        self.log_dir = os.path.join(self.log_dir, 'tensorboard')\n",
    "        os.makedirs(self.log_dir, exist_ok=True)\n",
    "        super().set_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MCIC20rEjHuX"
   },
   "source": [
    "<a name=\"Model-Settings\"></a>\n",
    "### Model Settings\n",
    "[[Return to ToC]](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8yFAj8qsjHuX",
    "outputId": "02b30f36-93ad-403b-a81a-e3fba2e61aef"
   },
   "outputs": [],
   "source": [
    "#  Use the full Skinny model with inception and dense blocks\n",
    "model_name = 'Skinny'\n",
    "\n",
    "#  Model settings\n",
    "levels = 6\n",
    "initial_filters = 19\n",
    "image_channels = 3\n",
    "\n",
    "#  Train settings\n",
    "max_epochs = 200\n",
    "initial_lr = 1e-4\n",
    "batch_size = 3\n",
    "patience = 10 #  use 50 for training on dark skintones\n",
    "\n",
    "#  Log Dir\n",
    "log_dir = 'logs'\n",
    "\n",
    "#  Preprocessing operations\n",
    "preprocessor = Preprocessor()\n",
    "preprocessor.cast(dtype=tf.float32).normalize().downscale(max_pixel_count=512**2).pad(network_levels=levels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fh2jyKzOjHuX"
   },
   "source": [
    "<a name=\"Model-Functions\"></a>\n",
    "### Model Functions\n",
    "[[Return to ToC]](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SYfFoxUQwkyc"
   },
   "source": [
    "Train, Test, Predict functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "PihDiykfwk2v"
   },
   "outputs": [],
   "source": [
    "def train_function(model: Model, batch_size: int, dataset_dir: str, patience: int) -> None:\n",
    "    data_loader = DataLoader(dataset_dir=dataset_dir, batch_size=batch_size, preprocessor=preprocessor)\n",
    "    trainer = Trainer(data_loader=data_loader, model=model, evaluate_test_data=True)\n",
    "    trainer.add_losses([K.binary_crossentropy, dice_loss])\n",
    "    trainer.add_metrics([\n",
    "        f1,\n",
    "        iou,\n",
    "        precision,\n",
    "        recall\n",
    "    ])\n",
    "    trainer.add_callbacks([\n",
    "        ModelCheckpoint(filepath=model.get_logdir(), verbose=1, save_best_only=True,\n",
    "                                  monitor='val_f1', mode='max', save_weight_only=False),#save_weights_only=True),\n",
    "        ReduceLROnPlateau(monitor='val_f1', factor=0.5, verbose=1, mode='max', min_lr=1e-6, patience=5),\n",
    "        EarlyStopping(monitor='val_f1', mode='max', patience=patience, verbose=1),\n",
    "        TensorBoard(log_dir=model.get_logdir(), histogram_freq=5)\n",
    "    ])\n",
    "\n",
    "    trainer.train(max_epochs, tf.keras.optimizers.Adam(learning_rate=initial_lr), verbose=1)\n",
    "\n",
    "def test_function(model: Model, dataset_dir: str) -> None:\n",
    "    data_loader = DataLoader(dataset_dir=dataset_dir, batch_size=1, preprocessor=preprocessor)\n",
    "    trainer = Trainer(data_loader=data_loader, model=model, evaluate_test_data=True)\n",
    "    trainer.add_losses([K.binary_crossentropy, dice_loss])\n",
    "    trainer.add_metrics([\n",
    "        f1,\n",
    "        iou,\n",
    "        precision,\n",
    "        recall\n",
    "    ])\n",
    "\n",
    "    model.get_model()\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=initial_lr)\n",
    "    model.keras_model.compile(optimizer=optimizer, loss=trainer.combined_loss(), metrics=trainer.metrics)\n",
    "    evaluation_metrics = model.keras_model.evaluate(data_loader.test_dataset, verbose=1)\n",
    "    evaluation_metrics = dict(zip(model.keras_model.metrics_names, evaluation_metrics))\n",
    "    print(evaluation_metrics)\n",
    "\n",
    "def save_x(model: Model, dataset_dir: str, preprocessor: Preprocessor, out_dir: str = 'x', skip = 0) -> None:\n",
    "    '''\n",
    "    Save Skinny X pre-processed images (512**2) to files\n",
    "    Save the images after the pre-processing, before they enter the model\n",
    "    \n",
    "    Image names are defined by a counter, which starts at skip\n",
    "    '''\n",
    "    data_loader = DataLoader(dataset_dir=dataset_dir, batch_size=1, preprocessor=preprocessor)\n",
    "\n",
    "    os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "    i = skip\n",
    "    for entry in data_loader.test_dataset:\n",
    "        i += 1\n",
    "\n",
    "        entry = entry[0]          #  dict: {'feature': data, dtype=float32}\n",
    "        entry = entry['feature']  #  shape=(1, 320, 384, 1) dtype=float32\n",
    "        entry = entry[0]*255      #  reshape(320, 384, 3) and de-preprocess\n",
    "        \n",
    "        #  Convert to numpy array or cv2.imwrite doesn't work\n",
    "        entry = np.array(entry)\n",
    "        #  cv2 works with BGR, not RGB\n",
    "        entry = cv2.cvtColor(entry, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        #  Save to a file\n",
    "        filename = f\"{i}.png\"\n",
    "        cv2.imwrite(os.path.join(out_dir, filename), entry)\n",
    "        #tf.keras.preprocessing.image.save_img(os.path.join(out_dir, filename), entry)\n",
    "        # https://stackoverflow.com/a/61041738\n",
    "\n",
    "def save_y(model: Model, dataset_dir: str, preprocessor: Preprocessor, out_dir: str = 'y', skip = 0) -> None:\n",
    "    '''\n",
    "    Save Skinny Y pre-processed-images (512**2) to files\n",
    "    Save the images after the pre-processing, before they enter the model\n",
    "    \n",
    "    Image names are defined by a counter, which starts at skip\n",
    "    '''\n",
    "    data_loader = DataLoader(dataset_dir=dataset_dir, batch_size=1, preprocessor=preprocessor)\n",
    "\n",
    "    os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "    i = skip\n",
    "    for entry in data_loader.test_dataset:\n",
    "        i += 1\n",
    "\n",
    "        entry = entry[1]        #  dict: {'label': data, dtype=float32}\n",
    "        entry = entry['label']  #  shape=(1, 320, 384, 1) dtype=float32\n",
    "        entry = entry[0]*255    #  reshape(320, 384, 1) and de-preprocess\n",
    "        \n",
    "        # Convert to numpy array or cv2.imwrite doesn't work\n",
    "        entry = np.array(entry)\n",
    "\n",
    "        # save to a file\n",
    "        filename = f\"{i}.png\"\n",
    "        cv2.imwrite(os.path.join(out_dir, filename), entry)\n",
    "\n",
    "def predict_function(model: Model, dataset_dir: str, out_dir: str, skip = 0) -> None:\n",
    "    data_loader = DataLoader(dataset_dir=dataset_dir, batch_size=1, preprocessor=preprocessor)\n",
    "    model.get_model()\n",
    "    os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "    #  Predict on test images\n",
    "    i = skip\n",
    "    for entry in data_loader.test_dataset:\n",
    "        i += 1\n",
    "        entry = entry[0]  #  dict: {'feature': data, 'types': float32}\n",
    "\n",
    "        #  Convert to tensor to prevent memory leak https://stackoverflow.com/a/64765018\n",
    "        tensor = tf.convert_to_tensor(entry['feature'], dtype=tf.float32)\n",
    "        #  Predict from feature image (X)\n",
    "        #pred = model.keras_model.predict(tensor) # predict from feature image (X)\n",
    "        pred = model.keras_model(tensor)\n",
    "        #print(pred)  #  debug\n",
    "\n",
    "        pred = pred[0]*255 #  reshape and de-preprocess\n",
    "        #print(pred)  #  debug\n",
    "        pred = pred.numpy()\n",
    "\n",
    "        #  Save to a file\n",
    "        filename = f\"{i}.png\"\n",
    "        cv2.imwrite(os.path.join(out_dir, filename), pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gvDuS90rQgNY"
   },
   "source": [
    "Models loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "-KjanqfQn1YY"
   },
   "outputs": [],
   "source": [
    "def load_checkpoint(checkpoint_filepath):\n",
    "    '''Import a model's files to set it as current model'''\n",
    "    out = None\n",
    "    ext = os.path.splitext(checkpoint_filepath)[1]\n",
    "    from_path = os.path.join(os.path.dirname(checkpoint_filepath), '.')\n",
    "\n",
    "    if ext == '.chkp':\n",
    "        to_path = 'logs/Skinny/checkpoint'\n",
    "        out = 'chkp'\n",
    "    elif ext == '.pb':\n",
    "        to_path = 'logs/Skinny/checkpoint/saved_model.pb'\n",
    "        out = 'pb'\n",
    "    else:\n",
    "        print(f'Unknown model filetype: {ext}')\n",
    "    \n",
    "    !rm -rf logs/Skinny/checkpoint  #  Clear checkpoints\n",
    "    !mkdir -p $to_path              #  Make default model folder\n",
    "    !cp -r $from_path $to_path      #  Copy the model files\n",
    "    \n",
    "    return out\n",
    "\n",
    "def load_schmugge_skintone_split(skintone):\n",
    "    '''Replace Schmugge CSV file with a predefined skintone split'''\n",
    "    assert skintone in skintones, f'Invalid skintone: {skintone}'\n",
    "    !rm dataset/Schmugge/data.csv\n",
    "    \n",
    "    if skintone == 'dark':\n",
    "        !cp drive/MyDrive/training/skinny/checkpoint-20210523-110554/dark2305_1309.csv dataset/Schmugge/data.csv\n",
    "    elif skintone == 'medium':\n",
    "        !cp drive/MyDrive/training/skinny/checkpoint-20210523-112308/medium2305_1323.csv dataset/Schmugge/data.csv\n",
    "    elif skintone == 'light':\n",
    "        !cp drive/MyDrive/training/skinny/checkpoint-20210523-122027/light2305_1420.csv dataset/Schmugge/data.csv\n",
    "    \n",
    "    print(f'{skintone}(sch) split imported!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_WYo2EjMjHuY"
   },
   "source": [
    "<a name=\"Use-Skin-Detector\"></a>\n",
    "# Use Skin Detector\n",
    "[[Return to ToC]](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rH_ZLsuMjHuY"
   },
   "source": [
    "<a name=\"Train\"></a>\n",
    "### Train\n",
    "[[Return to ToC]](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R0s_UkxKlnvN",
    "outputId": "7c53722d-6573-4fce-b39e-867fc6aedfaa"
   },
   "outputs": [],
   "source": [
    "dataset_dir = 'dataset/Pratheepan'\n",
    "\n",
    "\n",
    "#mod = Skinny(levels, initial_filters, image_channels, log_dir, load_checkpoint=True, model_name=model_name)\n",
    "mod = Skinny(levels, initial_filters, image_channels, log_dir)  # creates new model\n",
    "\n",
    "scheduler = WorkScheduler()\n",
    "scheduler.add_data(mod, train_function, batch_size = batch_size, dataset_dir = dataset_dir, patience = patience)\n",
    "scheduler.do_work()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u8cAzXpwyq_T"
   },
   "source": [
    "<a name=\"Test\"></a>\n",
    "### Test\n",
    "[[Return to ToC]](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V_3XkHNzyrOq",
    "outputId": "e55cdea5-f76c-47cb-978a-3436b69bdf9d"
   },
   "outputs": [],
   "source": [
    "chkp_ext = load_checkpoint(models['schmugge'])\n",
    "#chkp_ext = load_checkpoint('drive/MyDrive/training/skinny/checkpoint-20220320-183637/saved_model.ckpt/saved_model.pb')\n",
    "dataset_dir = 'dataset/ECU'\n",
    "\n",
    "\n",
    "mod = Skinny(levels, initial_filters, image_channels, log_dir, load_checkpoint=True,\n",
    "             model_name=model_name, checkpoint_extension=chkp_ext)\n",
    "\n",
    "scheduler = WorkScheduler()\n",
    "scheduler.add_data(mod, test_function, dataset_dir = dataset_dir)\n",
    "scheduler.do_work()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kmb_fL8mTQ7o"
   },
   "source": [
    "<a name=\"Predict\"></a>\n",
    "### Predict\n",
    "[[Return to ToC]](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jXLw51W2jHuZ"
   },
   "source": [
    "Utils functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "kbRzgInCPH2K"
   },
   "outputs": [],
   "source": [
    "def pred_dirs(out_dir: str) -> list:\n",
    "    x_dir = os.path.join(out_dir, 'x')\n",
    "    y_dir = os.path.join(out_dir, 'y')\n",
    "    pred_dir = os.path.join(out_dir, 'p')\n",
    "    return x_dir, y_dir, pred_dir\n",
    "\n",
    "def schedule_predict(model, dataset_dir: str, out_dir: str, skip: int = 0):\n",
    "    x_dir, y_dir, pred_dir = pred_dirs(out_dir)\n",
    "    scheduler = WorkScheduler()\n",
    "    scheduler.add_data(None, save_x, dataset_dir = dataset_dir, out_dir = x_dir, preprocessor = preprocessor, skip = skip)\n",
    "    scheduler.add_data(None, save_y, dataset_dir = dataset_dir, out_dir = y_dir,  preprocessor = preprocessor, skip = skip)\n",
    "    scheduler.add_data(model, predict_function, dataset_dir = dataset_dir, out_dir = pred_dir, skip = skip)\n",
    "    scheduler.do_work()\n",
    "\n",
    "def cross_predict(train_db, predict_db, timestr = None, save = False):\n",
    "    '''Perform a cross prediction of a normal model over a normal dataset'''\n",
    "    is_ecu = False\n",
    "    if predict_db == 'ecu':\n",
    "        predict_db = 'dataset/ECU'\n",
    "        is_ecu = True\n",
    "    elif predict_db == 'hgr':\n",
    "        predict_db = 'dataset/HGR_small'\n",
    "    elif predict_db == 'schmugge':\n",
    "        predict_db = 'dataset/Schmugge'\n",
    "    \n",
    "    if timestr == None:\n",
    "        timestr = get_timestamp()\n",
    "\n",
    "    #  Set the whole dataset as the testing set\n",
    "    whole_test = os.path.join(predict_db, 'data.csv') #  dataset to process\n",
    "    \n",
    "    #  limit ecu to 2000 predictions or ram crashes, do it 2 times\n",
    "    if is_ecu:\n",
    "        csv_full_test(whole_test, 2000)\n",
    "    else:\n",
    "        csv_full_test(whole_test)\n",
    "\n",
    "    #  Load model files\n",
    "    chkp_ext = load_checkpoint(models[train_db])\n",
    "    mod = Skinny(levels, initial_filters, image_channels, log_dir, load_checkpoint=True,\n",
    "            model_name=model_name, checkpoint_extension=chkp_ext)\n",
    "\n",
    "    #  Predict\n",
    "    ds_name = os.path.basename(predict_db).lower()\n",
    "    if ds_name == 'hgr_small':\n",
    "        ds_name = 'hgr'\n",
    "\n",
    "    out_dir = os.path.join(timestr, 'skinny', 'cross', f'{train_db}_on_{ds_name}')\n",
    "    schedule_predict(mod, predict_db, out_dir)\n",
    "\n",
    "    if is_ecu: #  time to do second half\n",
    "        csv_not_test(whole_test)\n",
    "        out_dir = os.path.join(timestr, 'skinny', 'cross', f'{train_db}_on_{ds_name}')\n",
    "        schedule_predict(mod, predict_db, out_dir, skip = 2000)\n",
    "\n",
    "    #  Zip and save predictions\n",
    "    if save:\n",
    "        zip_path = 'drive/MyDrive/testing/skinny/' + timestr + '_p.zip'\n",
    "        !zip -r $zip_path $timestr\n",
    "\n",
    "def cross_predict_skintones(train_skintone, predict_skintone, timestr = None, save = False):\n",
    "    '''Perform a cross prediction of a skintone model over a skintone dataset'''\n",
    "    db_dir = 'dataset/Schmugge'\n",
    "\n",
    "    if timestr == None:\n",
    "        timestr = get_timestamp()\n",
    "\n",
    "    #  Update the csv file to set the prediction set\n",
    "    gen_sch_by_skintone(predict_skintone, 'test')\n",
    "\n",
    "    #  Load model files\n",
    "    chkp_ext = load_checkpoint(models[train_skintone])\n",
    "    mod = Skinny(levels, initial_filters, image_channels, log_dir, load_checkpoint=True,\n",
    "            model_name=model_name, checkpoint_extension=chkp_ext)\n",
    "\n",
    "    #  Predict\n",
    "    out_dir = os.path.join(timestr, 'skinny', 'cross', f'{train_skintone}_on_{predict_skintone}')\n",
    "    schedule_predict(mod, db_dir, out_dir)\n",
    "\n",
    "    #  Zip and save predictions\n",
    "    if save:\n",
    "        zip_path = 'drive/MyDrive/testing/skinny/' + timestr + '_p.zip'\n",
    "        !zip -r $zip_path $timestr\n",
    "\n",
    "def base_predict(db_name, timestr = None, save = False):\n",
    "    '''Perform a base prediction of a model over a dataset'''\n",
    "    if db_name == 'ecu':\n",
    "        db_dir = 'dataset/ECU'\n",
    "    elif db_name == 'hgr':\n",
    "        db_dir = 'dataset/HGR_small'\n",
    "    elif db_name == 'schmugge':\n",
    "        db_dir = 'dataset/Schmugge'\n",
    "    elif db_name in skintones:\n",
    "        db_dir = 'dataset/Schmugge'\n",
    "        load_schmugge_skintone_split(db_name) #  Load skintone split\n",
    "    \n",
    "    if timestr == None:\n",
    "        timestr = get_timestamp()\n",
    "    \n",
    "    #  Load model files\n",
    "    chkp_ext = load_checkpoint(models[db_name])\n",
    "    mod = Skinny(levels, initial_filters, image_channels, log_dir, load_checkpoint=True,\n",
    "            model_name=model_name, checkpoint_extension=chkp_ext)\n",
    "\n",
    "    #  Predict\n",
    "    out_dir = os.path.join(timestr, 'skinny', 'base', db_name)\n",
    "    schedule_predict(mod, db_dir, out_dir)\n",
    "\n",
    "    #  Zip and save predictions\n",
    "    if save:\n",
    "        zip_path = 'drive/MyDrive/testing/skinny/' + timestr + '_p.zip'\n",
    "        !zip -r $zip_path $timestr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_u-MSM2PjHua"
   },
   "source": [
    "Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "57CE3vNEIRnS",
    "outputId": "19837fad-a2d9-41af-825e-ececa3121444"
   },
   "outputs": [],
   "source": [
    "# Custom Predict\n",
    "cross_predict('ecu', 'dataset/Pratheepan', timestr = get_timestamp(), save = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h8a0vl2eWcbG",
    "outputId": "f01bfb34-b619-4b88-9345-9cfcdcdcd083"
   },
   "outputs": [],
   "source": [
    "# Run thesis predictions\n",
    "\n",
    "# Do base+cross of either skintones or normal\n",
    "mode = 'normal' #  'normal' or 'skintones'\n",
    "\n",
    "\n",
    "timestr = get_timestamp()\n",
    "\n",
    "if mode == 'normal':\n",
    "    modls = ['ecu', 'hgr', 'schmugge']\n",
    "\n",
    "    #  Base predictions: based on splits defined by me and only predict on self\n",
    "    #  timestr/skinny/base/{ecu,hgr,schmugge}/{p/y/x}\n",
    "    for ds_name in modls:\n",
    "        base_predict(ds_name, timestr = timestr, save = False)\n",
    "\n",
    "    #  Cross predictions: use a dataset whole as the testing set\n",
    "    #  timestr/skinny/cross/ecu_on_ecu/{p/y/x}\n",
    "    for ds_train in modls:\n",
    "        for ds_test in modls:\n",
    "            if ds_train != ds_test: #  do not cross-predict on self\n",
    "                cross_predict(ds_train, ds_test, timestr = timestr, save = False)\n",
    "elif mode == 'skintones':\n",
    "    modls = ['light', 'medium', 'dark']\n",
    "\n",
    "    #  Base predictions: based on splits defined by me and only predict on self\n",
    "    #  timestr/skinny/base/{ecu,hgr,schmugge}/{p/y/x}\n",
    "    for ds_name in modls:\n",
    "        base_predict(ds_name, timestr = timestr, save = False)\n",
    "\n",
    "    #  Cross predictions: use a dataset whole as the testing set\n",
    "    #  timestr/skinny/cross/ecu_on_ecu/{p/y/x}\n",
    "    for ds_train in modls:\n",
    "        for ds_test in modls:\n",
    "            if ds_train != ds_test: #  do not cross-predict on self\n",
    "                cross_predict_skintones(ds_train, ds_test, timestr = timestr, save = False)\n",
    "\n",
    "#  Zip and save predictions\n",
    "zip_path = 'drive/MyDrive/testing/skinny/' + timestr + '_p.zip'\n",
    "!zip -r $zip_path $timestr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0b7v_S9Ms4Xt"
   },
   "source": [
    "Predict on a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YHyItKui-eRW",
    "outputId": "56d8859f-dbda-40fe-c701-a2b3d5f1de19"
   },
   "outputs": [],
   "source": [
    "# preprocessing operations\n",
    "preprocessor = Preprocessor()\n",
    "preprocessor.cast(dtype=tf.float32).normalize().downscale(max_pixel_count=512**2).pad(network_levels=levels)\n",
    "\n",
    "chkp_ext = load_checkpoint(models['ecu'])\n",
    "inim = 'dataset/ECU/origin_images/im00001.jpg'\n",
    "outim = 'spred/im00001.png'\n",
    "\n",
    "\n",
    "mod = Skinny(levels, initial_filters, image_channels, log_dir, load_checkpoint=True,\n",
    "        model_name=model_name, checkpoint_extension=chkp_ext)\n",
    "single_predict(mod, inim, outim, preprocessor)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "VoQkmwq6jHtx",
    "R4SmknMxjHt_",
    "MCIC20rEjHuX",
    "kmb_fL8mTQ7o"
   ],
   "name": "Skinny.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
